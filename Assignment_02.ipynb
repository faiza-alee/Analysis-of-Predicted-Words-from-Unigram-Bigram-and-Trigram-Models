{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "xZJ79ExggjrX"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import random\n",
        "from nltk import bigrams, trigrams\n",
        "from collections import Counter, defaultdict\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"punkt\")\n",
        "nltk.download('gutenberg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qh4jfrRmguLN",
        "outputId": "c40fa081-c5b2-4908-e566-6e083fb4090e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import gutenberg\n",
        "corpus = gutenberg.sents(\"austen-emma.txt\")[:1000]"
      ],
      "metadata": {
        "id": "2Iq-GAO7gxS9"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flat_corpus = [word.lower() for sentence in corpus for word in sentence if word.isalpha()]"
      ],
      "metadata": {
        "id": "1TW50H33g0Il"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unigram Model"
      ],
      "metadata": {
        "id": "ablrcPOci50S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_counts = Counter(flat_corpus)\n",
        "total_unigrams = sum(unigram_counts.values())"
      ],
      "metadata": {
        "id": "j1eTiLs2g2bu"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bigram Model"
      ],
      "metadata": {
        "id": "IOGfj3ZSi02E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_counts = Counter(bigrams(flat_corpus))\n",
        "total_bigrams = sum(bigram_counts.values())\n"
      ],
      "metadata": {
        "id": "F3fOsK5dg7Ui"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trigram Model"
      ],
      "metadata": {
        "id": "HitbHy2DixVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trigram_counts = Counter(trigrams(flat_corpus))\n",
        "total_trigrams = sum(trigram_counts.values())"
      ],
      "metadata": {
        "id": "6q_4_jvQg9Nb"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_unigram():\n",
        "    next_word = random.choices(list(unigram_counts.keys()), weights=unigram_counts.values())[0]\n",
        "    return next_word"
      ],
      "metadata": {
        "id": "uJqt2nwsg-yi"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_bigram(sequence):\n",
        "    last_word = sequence[-1]\n",
        "    possible_bigrams = {bigram[1]: count for bigram, count in bigram_counts.items() if bigram[0] == last_word}\n",
        "    if possible_bigrams:\n",
        "        next_word = random.choices(list(possible_bigrams.keys()), weights=possible_bigrams.values())[0]\n",
        "    else:\n",
        "        next_word = predict_unigram()  # Fallback to unigram if no bigram is available\n",
        "    return next_word"
      ],
      "metadata": {
        "id": "Y5-WnLV4hBxY"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_trigram(sequence):\n",
        "\n",
        "    last_bigram = tuple(sequence[-2:])\n",
        "    possible_trigrams = {trigram[2]: count for trigram, count in trigram_counts.items() if trigram[:2] == last_bigram}\n",
        "    if possible_trigrams:\n",
        "        next_word = random.choices(list(possible_trigrams.keys()), weights=possible_trigrams.values())[0]\n",
        "    else:\n",
        "        next_word = predict_bigram(sequence)\n",
        "    return next_word"
      ],
      "metadata": {
        "id": "u3HPynmnhExP"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sequences = [\n",
        "    [\"the\"], [\"data\"], [\"machine\", \"learning\"], [\"artificial\", \"intelligence\"],\n",
        "    [\"deep\", \"learning\"], [\"in\", \"the\"], [\"language\", \"model\"], [\"the\", \"future\", \"of\"],\n",
        "    [\"predictive\"], [\"modeling\", \"and\"]\n",
        "]"
      ],
      "metadata": {
        "id": "IjM1xIJ2h0FD"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for sequence in sample_sequences:\n",
        "    if len(sequence) == 1:\n",
        "        # Unigram Prediction\n",
        "        unigram_pred = predict_unigram()\n",
        "        # Bigram Prediction\n",
        "        bigram_pred = predict_bigram(sequence)\n",
        "        # Trigram Prediction - Not applicable for single-word sequences\n",
        "        trigram_pred = \"N/A (requires 2 words)\"\n",
        "    elif len(sequence) == 2:\n",
        "        unigram_pred = predict_unigram()\n",
        "        bigram_pred = predict_bigram(sequence)\n",
        "        trigram_pred = predict_trigram(sequence)\n",
        "    else:\n",
        "        unigram_pred, bigram_pred, trigram_pred = \"N/A\", \"N/A\", \"N/A\"\n",
        "    results.append((sequence, unigram_pred, bigram_pred, trigram_pred))\n",
        "\n"
      ],
      "metadata": {
        "id": "BRl0GPdFhIVX"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display Results in a Table Format"
      ],
      "metadata": {
        "id": "OwocZqu3igAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{'Sequence of Words':<25} {'Unigram Prediction':<20} {'Bigram Prediction':<20} {'Trigram Prediction':<20}\")\n",
        "for seq, uni, bi, tri in results:\n",
        "    seq_str = \" \".join(seq)\n",
        "    print(f\"{seq_str:<25} {uni:<20} {bi:<20} {tri:<20}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O43vFTEwicsa",
        "outputId": "c35365bf-b2c5-4544-ef8c-ffdbf7f5c30a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequence of Words         Unigram Prediction   Bigram Prediction    Trigram Prediction  \n",
            "the                       mr                   young                N/A (requires 2 words)\n",
            "data                      his                  never                N/A (requires 2 words)\n",
            "machine learning          a                    a                    the                 \n",
            "artificial intelligence   height               small                it                  \n",
            "deep learning             light                again                the                 \n",
            "in the                    and                  other                right               \n",
            "language model            were                 mr                   mr                  \n",
            "the future of             N/A                  N/A                  N/A                 \n",
            "predictive                than                 had                  N/A (requires 2 words)\n",
            "modeling and              sink                 said                 saying              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EDcC2ExPhtQU"
      },
      "execution_count": 36,
      "outputs": []
    }
  ]
}